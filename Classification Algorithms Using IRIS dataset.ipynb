{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f927948",
   "metadata": {},
   "source": [
    "Problem Description\n",
    "Use sklearn.datasets iris flower dataset to train your model using logistic regression. You need\n",
    "to figure out the accuracy of your model and use that to predict different samples in your test\n",
    "dataset. In iris dataset there are 150 samples containing following features,\n",
    "1. Sepal Length\n",
    "2. Sepal Width\n",
    "3. Petal length\n",
    "4. Petal width\n",
    "Using above 4 features you will classify a flower in one of the three categories,\n",
    "1. Setosa\n",
    "2. Versicolour\n",
    "3. Virginica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4970b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,confusion_matrix,f1_score,classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "print(\"Dir : \",dir(iris))\n",
    "print(\"Feature_names : \",iris.feature_names)\n",
    "print(\"Target_names  : \",iris.target_names)\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['Category'] = iris.target\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8032c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of this dataset is  (150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of this dataset is \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c42cbb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of elements in this dataset is  750\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of elements in this dataset is \",df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69d5ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   Category           150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f98ef",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce34997a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "142                5.8               2.7                5.1               1.9   \n",
       "\n",
       "     Category  \n",
       "142         2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "379c18bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sepal length (cm), sepal width (cm), petal length (cm), petal width (cm), Category]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fa1eb",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a3ccfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 119 samples in the training set and 30 samples in the test set\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df[iris.feature_names],df[\"Category\"], test_size=0.2)\n",
    "print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ef226",
   "metadata": {},
   "source": [
    "# Different types of Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f6819",
   "metadata": {},
   "source": [
    "# 1 - Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "903189f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  0.9747899159663865\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression()\n",
    "LRmodel.fit(X_train, Y_train)\n",
    "LRmodel_Pred = LRmodel.predict(X_test)\n",
    "print(\"Train Score : \",LRmodel.score(X_train,Y_train))\n",
    "print(\"Score : \",LRmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, LRmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, LRmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, LRmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, LRmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53897dd",
   "metadata": {},
   "source": [
    "# 2 - Decision Tree Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26affccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  1.0\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTmodel = DecisionTreeClassifier()\n",
    "DTmodel.fit(X_train,Y_train)\n",
    "DTmodel_Pred = DTmodel.predict(X_test)\n",
    "print(\"Train Score : \",DTmodel.score(X_train,Y_train))\n",
    "print(\"Score : \",DTmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, DTmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, DTmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, DTmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, DTmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b9037",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning of Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f457e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features='sqrt',\n",
      "                       splitter='random')\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9583333333333334\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'splitter': 'random'}\n",
      "\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "240 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.91666667 0.84094203 0.92463768 0.80652174\n",
      "        nan        nan 0.93333333 0.87391304 0.89927536 0.84094203\n",
      "        nan        nan 0.92463768 0.84818841 0.91666667 0.89094203\n",
      "        nan        nan 0.92463768 0.87463768 0.94166667 0.91666667\n",
      "        nan        nan 0.94166667 0.94166667 0.92463768 0.95\n",
      "        nan        nan 0.94130435 0.925      0.93297101 0.9076087\n",
      "        nan        nan 0.93297101 0.91594203 0.91630435 0.93297101\n",
      "        nan        nan 0.94130435 0.89963768 0.94963768 0.93297101\n",
      "        nan        nan 0.93297101 0.825      0.92463768 0.83913043\n",
      "        nan        nan 0.93297101 0.89130435 0.91594203 0.84818841\n",
      "        nan        nan 0.91630435 0.87463768 0.91630435 0.89927536\n",
      "        nan        nan 0.925      0.925      0.94166667 0.94166667\n",
      "        nan        nan 0.94166667 0.92427536 0.89963768 0.91630435\n",
      "        nan        nan 0.94130435 0.90797101 0.95       0.92463768\n",
      "        nan        nan 0.90797101 0.92463768 0.89963768 0.91630435\n",
      "        nan        nan 0.9326087  0.95833333 0.94130435 0.90797101\n",
      "        nan        nan 0.91666667 0.8826087  0.95       0.89891304\n",
      "        nan        nan 0.95       0.89963768 0.95797101 0.80797101\n",
      "        nan        nan 0.94130435 0.94094203 0.89166667 0.82282609\n",
      "        nan        nan 0.89927536 0.89094203 0.95833333 0.94927536\n",
      "        nan        nan 0.94166667 0.91666667 0.93297101 0.95\n",
      "        nan        nan 0.91666667 0.925      0.94166667 0.89927536\n",
      "        nan        nan 0.90797101 0.88333333 0.92427536 0.95\n",
      "        nan        nan 0.89166667 0.88333333 0.91666667 0.94130435]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parameter={\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'max_depth':[3,4,5,6,7,8,9,10],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'splitter':['best', 'random']\n",
    "}\n",
    "\n",
    "DTmodel = DecisionTreeClassifier()\n",
    "\n",
    "cv=GridSearchCV(DTmodel,parameter,scoring='accuracy')\n",
    "cv.fit(X_train,Y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",cv.best_params_)\n",
    "\n",
    "cv_model=cv.best_estimator_\n",
    "DTmodel.fit(X_train, Y_train)\n",
    "DTmodel_Pred = cv_model.predict(X_test)\n",
    "\n",
    "print(\"\\nScore : \",cv_model.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, DTmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, DTmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, DTmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, DTmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb9b7f",
   "metadata": {},
   "source": [
    "# 3 - Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "855b5d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  1.0\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "\n",
    "RFCmodel = RandomForestClassifier()\n",
    "\n",
    "\n",
    "RFCmodel.fit(X_train, Y_train)\n",
    "RFCmodel_Pred = RFCmodel.predict(X_test)\n",
    "\n",
    "print(\"Train Score : \",RFCmodel.score(X_train,Y_train))\n",
    "print(\"Score : \",RFCmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, RFCmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, RFCmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, RFCmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, RFCmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b2910",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning of Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72f3a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " RandomForestClassifier(max_depth=6, max_features=None, n_estimators=10)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9666666666666668\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'bootstrap': True, 'criterion': 'gini', 'max_depth': 6, 'max_features': None, 'n_estimators': 10}\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "parameter={\n",
    "    'n_estimators':[10,50,100],\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'max_depth':np.arange(2,10,2),\n",
    "    'max_features':[None,'sqrt','log2'],\n",
    "    \"bootstrap\": [True, False]\n",
    "    \n",
    "}\n",
    "\n",
    "RFCmodel = RandomForestClassifier()\n",
    "\n",
    "cv=GridSearchCV(RFCmodel,parameter,scoring='accuracy')\n",
    "cv.fit(X_train,Y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",cv.best_params_)\n",
    "\n",
    "cv_model=cv.best_estimator_\n",
    "cv_model.fit(X_train, Y_train)\n",
    "RFCmodel_Pred = cv_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Score : \",cv_model.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, RFCmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, RFCmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, RFCmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, RFCmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43bf3f8",
   "metadata": {},
   "source": [
    "# 4 - Ada Boost Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ff94a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  0.9747899159663865\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "AdaBCmodel = AdaBoostClassifier()\n",
    "AdaBCmodel.fit(X_train, Y_train)\n",
    "AdaBCmodel_Pred = AdaBCmodel.predict(X_test)\n",
    "print(\"Train Score : \",AdaBCmodel.score(X_train,Y_train))\n",
    "print(\"Score : \",AdaBCmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, AdaBCmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, AdaBCmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, AdaBCmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, AdaBCmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb19d0",
   "metadata": {},
   "source": [
    "# 5 - Gradient Boosting Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "013a9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  1.0\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBCmodel = GradientBoostingClassifier()\n",
    "GBCmodel.fit(X_train, Y_train)\n",
    "GBCmodel_Pred = GBCmodel.predict(X_test)\n",
    "print(\"Train Score : \",GBCmodel.score(X_train,Y_train))\n",
    "print(\"Score : \",GBCmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, GBCmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, GBCmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, GBCmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, GBCmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209eb1e",
   "metadata": {},
   "source": [
    "# 6 - XGB Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4716b9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  1.0\n",
      " Test Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "XGBmodel = xgb.XGBClassifier()\n",
    "XGBmodel.fit(X_train, Y_train)\n",
    "XGBmodel_Pred = XGBmodel.predict(X_test)\n",
    "print(\"Train Score : \",XGBmodel.score(X_train,Y_train))\n",
    "print(\" Test Score : \",XGBmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, XGBmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, XGBmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, XGBmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, XGBmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d370007",
   "metadata": {},
   "source": [
    "# 7 - SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0af77074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  0.9663865546218487\n",
      "Test Score :  0.9666666666666667\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "SVCmodel = SVC()\n",
    "SVCmodel.fit(X_train, Y_train)\n",
    "SVCmodel_Pred = SVCmodel.predict(X_test)\n",
    "print(\"Train Score : \",SVCmodel.score(X_train,Y_train))\n",
    "print(\"Test Score : \",SVCmodel.score(X_test,Y_test))\n",
    "#print(\"Accuracy_score : \",SVCmodel_Pred(Y_test, SVCmodel_Pred,average='macro'))\n",
    "#print('Confusion Matrix:\\n', SVCmodel_Pred(Y_test, LRmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, SVCmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, SVCmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b11a54b",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning of Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bb04918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " SVC(C=1, degree=2, gamma=0.001, kernel='linear')\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.975\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Score :  0.9666666666666667\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    'C': [0.1, 1, 3, 10],          \n",
    "    'gamma': [0.001, 0.01, 0.1],\n",
    "    'degree': [2, 3, 4, 5],\n",
    "    'kernel': ['linear','poly','rbf','sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "cv=GridSearchCV(SVCmodel,parameter,scoring='accuracy')\n",
    "cv.fit(X_train,Y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",cv.best_params_)\n",
    "\n",
    "cv_model=cv.best_estimator_\n",
    "cv_model.fit(X_train, Y_train)\n",
    "SVCmodel_Pred = cv_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Score : \",cv_model.score(X_test,Y_test))\n",
    "#print(\"Accuracy_score : \",accuracy_score(Y_test, SVCmodel_Pred))\n",
    "#print('Confusion Matrix:\\n', confusion_matrix(Y_test, SVCmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, SVCmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, SVCmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28590812",
   "metadata": {},
   "source": [
    "# 8 - KNeighbors Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1615949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :  0.9747899159663865\n",
      "Test Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      "Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNNmodel = KNeighborsClassifier()\n",
    "KNNmodel.fit(X_train, Y_train)\n",
    "KNNmodel_Pred = KNNmodel.predict(X_test)\n",
    "print(\"Train Score : \",KNNmodel.score(X_train,Y_train))\n",
    "print(\"Test Score : \",KNNmodel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, KNNmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, KNNmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, KNNmodel_Pred, average='macro'))\n",
    "print('Classification Report : \\n', classification_report(Y_test, KNNmodel_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89045bb9",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning of KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c06c2e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1024, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\Mathew\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1493, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " KNeighborsClassifier(n_neighbors=9, weights='distance')\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.975\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'algorithm': 'auto', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Score :  0.9666666666666667\n",
      "Accuracy_score :  0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "F1 score :  0.9658994032395567\n",
      " Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter={\n",
    "    'n_neighbors': [3, 5, 7, 9, 11], \n",
    "    'weights': ['uniform', 'distance',None],  \n",
    "    'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "KNNmodel = KNeighborsClassifier()\n",
    "\n",
    "cv=GridSearchCV(KNNmodel,parameter,scoring='accuracy')\n",
    "cv.fit(X_train,Y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",cv.best_params_)\n",
    "\n",
    "cv_model=cv.best_estimator_\n",
    "cv_model.fit(X_train, Y_train)\n",
    "KNNmodel_Pred = cv_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Score : \",cv_model.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, KNNmodel_Pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, KNNmodel_Pred))\n",
    "print('F1 score : ', f1_score(Y_test, KNNmodel_Pred, average='macro'))\n",
    "print(' Classification Report : \\n', classification_report(Y_test, KNNmodel_Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a265cfb",
   "metadata": {},
   "source": [
    "# 9 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32c5e856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of mislabelled datapoints : 0\n",
      "Score :  1.0\n",
      "Accuracy_score :  1.0\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "F1 score :  1.0\n",
      " Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NBCModel = GaussianNB()\n",
    "NBCModel.fit(X_train, Y_train)\n",
    "y_pred = NBCModel.predict(X_test)\n",
    "#print(y_pred)\n",
    "#print(Y_test)\n",
    "mislabel = np.sum(Y_test != y_pred)\n",
    "print(\"Total no of mislabelled datapoints :\",mislabel)\n",
    "\n",
    "print(\"Score : \",NBCModel.score(X_test,Y_test))\n",
    "print(\"Accuracy_score : \",accuracy_score(Y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_test, y_pred))\n",
    "print('F1 score : ', f1_score(Y_test, y_pred, average='macro'))\n",
    "print(' Classification Report : \\n',classification_report(y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8aca06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
